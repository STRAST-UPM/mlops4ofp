{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fase 05 \u2014 Modeling (Full Version)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# Fase 05 \u2014 Modeling (Full Notebook Version)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "from time import perf_counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from mlops4ofp.tools.run_context import (\n",
        "    detect_execution_dir,\n",
        "    detect_project_root,\n",
        "    assemble_run_context,\n",
        "    print_run_context,\n",
        ")\n",
        "from mlops4ofp.tools.params_manager import ParamsManager\n",
        "from mlops4ofp.tools.traceability import write_metadata\n",
        "from mlops4ofp.tools.artifacts import get_git_hash\n",
        "\n",
        "# ============================================================\n",
        "# CONTEXTO\n",
        "# ============================================================\n",
        "\n",
        "VARIANT = os.environ.get(\"ACTIVE_VARIANT\")\n",
        "if VARIANT is None:\n",
        "    raise RuntimeError(\"ACTIVE_VARIANT no definido (usar make nb5-run VARIANT=vNNN)\")\n",
        "\n",
        "PHASE = \"05_modeling\"\n",
        "t_start = perf_counter()\n",
        "\n",
        "execution_dir = detect_execution_dir()\n",
        "project_root = detect_project_root(execution_dir)\n",
        "\n",
        "pm = ParamsManager(PHASE, project_root)\n",
        "pm.set_current(VARIANT)\n",
        "variant_root = pm.current_variant_dir()\n",
        "\n",
        "ctx = assemble_run_context(\n",
        "    execution_dir, project_root, PHASE, VARIANT, variant_root\n",
        ")\n",
        "print_run_context(ctx)\n",
        "\n",
        "with open(variant_root / \"params.yaml\", \"r\") as f:\n",
        "    params = yaml.safe_load(f)\n",
        "\n",
        "parent_variant = params[\"parent_variant\"]\n",
        "model_family = params[\"model_family\"]\n",
        "\n",
        "# ============================================================\n",
        "# CARGA DATASET\n",
        "# ============================================================\n",
        "\n",
        "dataset_path = (\n",
        "    project_root\n",
        "    / \"executions\"\n",
        "    / \"04_targetengineering\"\n",
        "    / parent_variant\n",
        "    / \"04_targetengineering_dataset.parquet\"\n",
        ")\n",
        "\n",
        "df = pd.read_parquet(dataset_path)\n",
        "\n",
        "sequences = df[\"OW_events\"].tolist()\n",
        "y = df[\"label\"].values.astype(np.int32)\n",
        "\n",
        "# ============================================================\n",
        "# VECTORIZE (BoW simple)\n",
        "# ============================================================\n",
        "\n",
        "vocab = sorted(set(ev for s in sequences for ev in s))\n",
        "index = {ev: i for i, ev in enumerate(vocab)}\n",
        "\n",
        "X = np.zeros((len(sequences), len(vocab)), dtype=np.float32)\n",
        "for i, s in enumerate(sequences):\n",
        "    for ev in s:\n",
        "        X[i, index[ev]] += 1.0\n",
        "\n",
        "# ============================================================\n",
        "# SPLIT\n",
        "# ============================================================\n",
        "\n",
        "idx = np.arange(len(X))\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "split = params[\"evaluation\"][\"split\"]\n",
        "n = len(idx)\n",
        "n_train = int(split[\"train\"] * n)\n",
        "n_val = int(split[\"val\"] * n)\n",
        "\n",
        "train_idx = idx[:n_train]\n",
        "val_idx = idx[n_train:n_train+n_val]\n",
        "test_idx = idx[n_train+n_val:]\n",
        "\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "# ============================================================\n",
        "# EXPERIMENTOS (max_trials)\n",
        "# ============================================================\n",
        "\n",
        "max_trials = params[\"automl\"][\"max_trials\"]\n",
        "trials_summary = []\n",
        "\n",
        "best_recall = -1.0\n",
        "best_model = None\n",
        "best_hparams = None\n",
        "\n",
        "for trial in range(max_trials):\n",
        "\n",
        "    units = random.choice([32, 64])\n",
        "    lr = random.choice([0.001, 0.0005])\n",
        "    batch_size = random.choice([32, 64])\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(X.shape[1],)),\n",
        "        layers.Dense(units, activation=\"relu\"),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(lr),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[keras.metrics.Recall(name=\"recall\")]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=params[\"training\"][\"epochs\"],\n",
        "        batch_size=batch_size,\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    val_recall = float(max(history.history[\"val_recall\"]))\n",
        "\n",
        "    trials_summary.append({\n",
        "        \"trial_id\": trial,\n",
        "        \"hyperparameters\": {\n",
        "            \"units\": units,\n",
        "            \"learning_rate\": lr,\n",
        "            \"batch_size\": batch_size\n",
        "        },\n",
        "        \"val_recall\": val_recall\n",
        "    })\n",
        "\n",
        "    if val_recall > best_recall:\n",
        "        best_recall = val_recall\n",
        "        best_model = model\n",
        "        best_hparams = {\n",
        "            \"units\": units,\n",
        "            \"learning_rate\": lr,\n",
        "            \"batch_size\": batch_size\n",
        "        }\n",
        "\n",
        "# ============================================================\n",
        "# GUARDAR MODELO FINAL\n",
        "# ============================================================\n",
        "\n",
        "final_model_path = variant_root / \"model_final.h5\"\n",
        "best_model.save(final_model_path)\n",
        "\n",
        "# ============================================================\n",
        "# METADATA COMPLETA\n",
        "# ============================================================\n",
        "\n",
        "metadata_path = variant_root / f\"{PHASE}_metadata.json\"\n",
        "\n",
        "metadata = {\n",
        "    \"phase\": PHASE,\n",
        "    \"variant\": VARIANT,\n",
        "    \"parent_variant\": parent_variant,\n",
        "    \"model_family\": model_family,\n",
        "    \"num_experiments\": max_trials,\n",
        "    \"best_val_recall\": best_recall,\n",
        "    \"best_hyperparameters\": best_hparams,\n",
        "    \"model_path\": str(final_model_path),\n",
        "    \"dataset_path\": str(dataset_path),\n",
        "    \"split_sizes\": {\n",
        "        \"train\": int(len(train_idx)),\n",
        "        \"val\": int(len(val_idx)),\n",
        "        \"test\": int(len(test_idx))\n",
        "    },\n",
        "    \"trials_summary\": trials_summary,\n",
        "    \"mlflow\": {\n",
        "        \"run_id\": None,\n",
        "        \"published\": False\n",
        "    },\n",
        "    \"git\": {\n",
        "        \"commit\": get_git_hash()\n",
        "    },\n",
        "    \"generated_at\": datetime.now(timezone.utc).isoformat()\n",
        "}\n",
        "\n",
        "with open(metadata_path, \"w\") as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "write_metadata(\n",
        "    stage=PHASE,\n",
        "    variant=VARIANT,\n",
        "    parent_variant=parent_variant,\n",
        "    inputs=[str(dataset_path)],\n",
        "    outputs=[str(metadata_path)],\n",
        "    params=params,\n",
        "    metadata_path=metadata_path,\n",
        ")\n",
        "\n",
        "print(f\"[DONE] Fase 05 completada en {perf_counter()-t_start:.1f}s\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}