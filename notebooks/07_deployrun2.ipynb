{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9c29bc",
   "metadata": {},
   "source": [
    "# F07 - Deploy & Runtime Validation (autocontenido)\n",
    "\n",
    "Este notebook implementa completamente la Fase 07 sin depender de `scripts/07_deployrun.py`.\n",
    "\n",
    "Flujo:\n",
    "1) prepare: genera `manifest.json` a partir de la variante F06 padre\n",
    "2) run: arranca servidor Flask (minimo), ejecuta cliente batch, guarda logs crudos (parquet+csv)\n",
    "3) postprocess: calcula metricas por modelo (`prediction_name`) incluyendo recuentos `no_ref_*`\n",
    "4) report: genera `report.html` y figuras en `report/figures/`\n",
    "5) traceability: escribe `07_deployrun_metadata.json`\n",
    "\n",
    "Propiedades:\n",
    "- Idempotente: al ejecutar run se regeneran `runtime/ logs/ metrics/ report/`.\n",
    "- Caja negra: servidor+cliente se ejecutan dentro del notebook como sistema de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615129e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:27.258809Z",
     "iopub.status.busy": "2026-02-16T21:55:27.258570Z",
     "iopub.status.idle": "2026-02-16T21:55:27.267647Z",
     "shell.execute_reply": "2026-02-16T21:55:27.267202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F07] VARIANT = v701\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Configuracion\n",
    "# ===============================\n",
    "import os\n",
    "\n",
    "VARIANT = os.getenv(\"ACTIVE_VARIANT\", \"v701\")   # <-- cambia por tu variante F07 (vNNN)\n",
    "\n",
    "DEFAULT_HOST = \"127.0.0.1\"\n",
    "DEFAULT_PORT = 5005\n",
    "\n",
    "print(f\"[F07] VARIANT = {VARIANT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f649e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:27.269874Z",
     "iopub.status.busy": "2026-02-16T21:55:27.269698Z",
     "iopub.status.idle": "2026-02-16T21:55:27.273702Z",
     "shell.execute_reply": "2026-02-16T21:55:27.273379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F07] project_root = /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Bootstrap: localizar project root\n",
    "# ===============================\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "for _ in range(10):\n",
    "    if (ROOT / \"mlops4ofp\").exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "else:\n",
    "    raise RuntimeError(\"No se pudo localizar project root (carpeta mlops4ofp)\")\n",
    "\n",
    "sys.path.insert(0, str(ROOT))\n",
    "print(\"[F07] project_root =\", ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5297be46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:27.275389Z",
     "iopub.status.busy": "2026-02-16T21:55:27.275288Z",
     "iopub.status.idle": "2026-02-16T21:55:30.788535Z",
     "shell.execute_reply": "2026-02-16T21:55:30.788130Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Imports (proyecto + deps)\n",
    "# ===============================\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, jsonify\n",
    "from werkzeug.serving import make_server\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlops4ofp.tools.params_manager import ParamsManager\n",
    "from mlops4ofp.tools.run_context import detect_execution_dir, detect_project_root\n",
    "from mlops4ofp.tools.traceability import write_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2d0c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.790958Z",
     "iopub.status.busy": "2026-02-16T21:55:30.790556Z",
     "iopub.status.idle": "2026-02-16T21:55:30.797056Z",
     "shell.execute_reply": "2026-02-16T21:55:30.796785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F07] variant_root = /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701\n",
      "[F07] parent_f06 = v601\n",
      "[F07] runtime = 127.0.0.1 5005\n",
      "[F07] sample_size = None (dataset completo)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Paths y utilidades\n",
    "# ===============================\n",
    "PHASE = \"07_deployrun\"\n",
    "\n",
    "def ensure_clean_dir(path: Path):\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def variant_root_from_pm(variant: str) -> Path:\n",
    "    execution_dir = detect_execution_dir()\n",
    "    project_root = detect_project_root(execution_dir)\n",
    "    pm = ParamsManager(PHASE, project_root)\n",
    "    pm.set_current(variant)\n",
    "    return pm.current_variant_dir()\n",
    "\n",
    "variant_root = variant_root_from_pm(VARIANT)\n",
    "print(\"[F07] variant_root =\", variant_root)\n",
    "\n",
    "params_path = variant_root / \"params.yaml\"\n",
    "if not params_path.exists():\n",
    "    raise FileNotFoundError(f\"No existe params.yaml para {PHASE}:{VARIANT} en {params_path}\")\n",
    "\n",
    "with open(params_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    f07_params = yaml.safe_load(f)\n",
    "\n",
    "parent_f06 = f07_params.get(\"parent_variant_f06\")\n",
    "if not parent_f06:\n",
    "    raise ValueError(\"parent_variant_f06 debe estar definido en params.yaml de F07\")\n",
    "\n",
    "runtime_cfg = (f07_params.get(\"runtime\") or {})\n",
    "HOST = runtime_cfg.get(\"host\", DEFAULT_HOST)\n",
    "PORT = int(runtime_cfg.get(\"port\", DEFAULT_PORT))\n",
    "\n",
    "# Parámetro para limitar número de ventanas procesadas\n",
    "SAMPLE_SIZE = f07_params.get(\"sample_size\")\n",
    "\n",
    "print(\"[F07] parent_f06 =\", parent_f06)\n",
    "print(\"[F07] runtime =\", HOST, PORT)\n",
    "if SAMPLE_SIZE:\n",
    "    print(f\"[F07] sample_size = {SAMPLE_SIZE} (modo prueba)\")\n",
    "else:\n",
    "    print(\"[F07] sample_size = None (dataset completo)\")\n",
    "\n",
    "runtime_dir = variant_root / \"runtime\"\n",
    "logs_dir = variant_root / \"logs\"\n",
    "metrics_dir = variant_root / \"metrics\"\n",
    "report_dir = variant_root / \"report\"\n",
    "figures_dir = report_dir / \"figures\"\n",
    "\n",
    "manifest_path = variant_root / \"manifest.json\"\n",
    "metadata_path = variant_root / f\"{PHASE}_metadata.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dba14",
   "metadata": {},
   "source": [
    "## 1) Prepare - generar manifest.json\n",
    "\n",
    "`manifest.json` es el contrato sellado de F07:\n",
    "- lista de modelos (por `prediction_name`)\n",
    "- directorio del modelo en el paquete F06 (con `model.h5` y `model_summary.json`)\n",
    "- dataset asociado (parquet F04 copiado en F06)\n",
    "- columnas (`OW_events`, `label`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2b966c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.798608Z",
     "iopub.status.busy": "2026-02-16T21:55:30.798494Z",
     "iopub.status.idle": "2026-02-16T21:55:30.806148Z",
     "shell.execute_reply": "2026-02-16T21:55:30.805895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] manifest.json generado en: /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/manifest.json\n",
      "[OK] modelos: 0 | datasets: 0\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Prepare: construir manifest.json\n",
    "# ===============================\n",
    "project_root = ROOT\n",
    "f06_root = project_root / \"executions\" / \"06_packaging\" / parent_f06\n",
    "if not f06_root.exists():\n",
    "    raise FileNotFoundError(f\"No existe paquete F06: {f06_root}\")\n",
    "\n",
    "f06_metadata_path = f06_root / \"06_packaging_metadata.json\"\n",
    "if not f06_metadata_path.exists():\n",
    "    candidates = list(f06_root.glob(\"*_metadata.json\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No se encontro metadata F06 en {f06_root}\")\n",
    "    f06_metadata_path = candidates[0]\n",
    "\n",
    "f06_metadata = json.loads(f06_metadata_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "models_manifest = []\n",
    "datasets_manifest = []\n",
    "\n",
    "datasets_dir_f06 = f06_root / \"datasets\"\n",
    "models_dir_f06 = f06_root / \"models\"\n",
    "\n",
    "seen_datasets = set()\n",
    "\n",
    "for m in f06_metadata.get(\"models\", []):\n",
    "    pred_name = m[\"prediction_name\"]\n",
    "    v05 = m[\"source_f05\"]\n",
    "\n",
    "    model_candidates = list(models_dir_f06.glob(f\"{pred_name}__*\"))\n",
    "    if len(model_candidates) != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Esperaba 1 directorio para modelo '{pred_name}' en {models_dir_f06}, encontrado: {model_candidates}\"\n",
    "        )\n",
    "    model_dir = model_candidates[0]\n",
    "    model_h5 = model_dir / \"model.h5\"\n",
    "    model_summary = model_dir / \"model_summary.json\"\n",
    "    if not model_h5.exists():\n",
    "        raise FileNotFoundError(f\"No existe model.h5 en {model_dir}\")\n",
    "    if not model_summary.exists():\n",
    "        raise FileNotFoundError(f\"No existe model_summary.json en {model_dir} (necesario para vectorizacion runtime)\")\n",
    "\n",
    "    f05_params_path = project_root / \"executions\" / \"05_modeling\" / v05 / \"params.yaml\"\n",
    "    if not f05_params_path.exists():\n",
    "        raise FileNotFoundError(f\"No existe params.yaml de F05 {v05}: {f05_params_path}\")\n",
    "    f05_params = yaml.safe_load(f05_params_path.read_text(encoding=\"utf-8\"))\n",
    "    v04 = f05_params[\"parent_variant\"]\n",
    "\n",
    "    dataset_path = datasets_dir_f06 / f\"{v04}__dataset.parquet\"\n",
    "    if not dataset_path.exists():\n",
    "        raise FileNotFoundError(f\"No existe dataset F04 copiado en F06: {dataset_path}\")\n",
    "\n",
    "    models_manifest.append({\n",
    "        \"prediction_name\": pred_name,\n",
    "        \"source_f05\": v05,\n",
    "        \"source_f04\": v04,\n",
    "        \"model_dir\": str(model_dir),\n",
    "        \"model_h5\": \"model.h5\",\n",
    "        \"model_summary\": \"model_summary.json\",\n",
    "        \"dataset_path\": str(dataset_path),\n",
    "        \"x_column\": \"OW_events\",\n",
    "        \"y_column\": \"label\",\n",
    "    })\n",
    "\n",
    "    if str(dataset_path) not in seen_datasets:\n",
    "        datasets_manifest.append({\n",
    "            \"dataset_path\": str(dataset_path),\n",
    "            \"x_column\": \"OW_events\",\n",
    "            \"y_column\": \"label\",\n",
    "            \"source_f04\": v04,\n",
    "        })\n",
    "        seen_datasets.add(str(dataset_path))\n",
    "\n",
    "manifest = {\n",
    "    \"phase\": PHASE,\n",
    "    \"variant\": VARIANT,\n",
    "    \"f06_variant\": parent_f06,\n",
    "    \"f06_path\": str(f06_root),\n",
    "    \"created_at\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"runtime\": {\"host\": HOST, \"port\": PORT},\n",
    "    \"models\": models_manifest,\n",
    "    \"datasets\": datasets_manifest,\n",
    "}\n",
    "\n",
    "manifest_path.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "print(\"[OK] manifest.json generado en:\", manifest_path)\n",
    "print(\"[OK] modelos:\", len(models_manifest), \"| datasets:\", len(datasets_manifest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a64f81",
   "metadata": {},
   "source": [
    "## 2) Run - servidor + cliente (batch) + logs crudos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f618e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.807600Z",
     "iopub.status.busy": "2026-02-16T21:55:30.807521Z",
     "iopub.status.idle": "2026-02-16T21:55:30.815331Z",
     "shell.execute_reply": "2026-02-16T21:55:30.815068Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Servidor Flask en thread (para notebook)\n",
    "# ===============================\n",
    "class ServerThread(Thread):\n",
    "    def __init__(self, app, host, port):\n",
    "        super().__init__(daemon=True)\n",
    "        self.server = make_server(host, port, app)\n",
    "        self.ctx = app.app_context()\n",
    "        self.ctx.push()\n",
    "\n",
    "    def run(self):\n",
    "        self.server.serve_forever()\n",
    "\n",
    "    def shutdown(self):\n",
    "        self.server.shutdown()\n",
    "\n",
    "\n",
    "def build_runtime_server(manifest: dict) -> Flask:\n",
    "    app = Flask(__name__)\n",
    "\n",
    "    loaded_models = []\n",
    "    for m in manifest[\"models\"]:\n",
    "        model_dir = Path(m[\"model_dir\"])\n",
    "        summary = json.loads((model_dir / m[\"model_summary\"]).read_text(encoding=\"utf-8\"))\n",
    "        model = tf.keras.models.load_model(model_dir / m[\"model_h5\"])\n",
    "\n",
    "        loaded_models.append({\n",
    "            \"prediction_name\": summary[\"prediction_name\"],\n",
    "            \"model\": model,\n",
    "            \"vectorization\": summary[\"vectorization\"],\n",
    "            \"threshold\": float(summary.get(\"threshold\", 0.5)),\n",
    "        })\n",
    "\n",
    "    def vectorize_dense_bow(window, cfg):\n",
    "        vocab = cfg[\"vocab\"]\n",
    "        input_dim = int(cfg[\"input_dim\"])\n",
    "        index = {int(ev): i for i, ev in enumerate(vocab)}\n",
    "        X = np.zeros((1, input_dim), dtype=np.float32)\n",
    "        for ev in window:\n",
    "            i = index.get(int(ev))\n",
    "            if i is not None:\n",
    "                X[0, i] += 1.0\n",
    "        return X\n",
    "\n",
    "    def vectorize_sequence(window, cfg):\n",
    "        vocab = cfg[\"vocab\"]\n",
    "        max_len = int(cfg[\"max_len\"])\n",
    "        index = {int(ev): i + 1 for i, ev in enumerate(vocab)}\n",
    "        seq = [index[int(e)] for e in window if int(e) in index]\n",
    "        seq = seq[-max_len:]\n",
    "        X = np.zeros((1, max_len), dtype=np.int32)\n",
    "        if len(seq) > 0:\n",
    "            X[0, -len(seq):] = np.array(seq, dtype=np.int32)\n",
    "        return X\n",
    "\n",
    "    def vectorize(window, cfg):\n",
    "        vtype = cfg.get(\"vectorization\")\n",
    "        if vtype == \"dense_bow\":\n",
    "            return vectorize_dense_bow(window, cfg)\n",
    "        if vtype == \"sequence\":\n",
    "            return vectorize_sequence(window, cfg)\n",
    "        raise ValueError(f\"Vectorization no soportada: {vtype}\")\n",
    "\n",
    "    @app.route(\"/infer\", methods=[\"POST\"])\n",
    "    def infer():\n",
    "        payload = request.get_json(force=True)\n",
    "        window = payload[\"window\"]\n",
    "        results = []\n",
    "        for m in loaded_models:\n",
    "            X = vectorize(window, m[\"vectorization\"])\n",
    "            y_prob = float(m[\"model\"].predict(X, verbose=0).ravel()[0])\n",
    "            y_pred = int(y_prob >= m[\"threshold\"])\n",
    "            results.append({\"prediction_name\": m[\"prediction_name\"], \"y_pred\": y_pred})\n",
    "        return jsonify({\"window\": window, \"results\": results})\n",
    "\n",
    "    @app.route(\"/control\", methods=[\"POST\"])\n",
    "    def control():\n",
    "        payload = request.get_json(force=True)\n",
    "        if payload.get(\"cmd\") == \"shutdown\":\n",
    "            return jsonify({\"status\": \"shutting_down\"})\n",
    "        return jsonify({\"status\": \"unknown_command\"})\n",
    "\n",
    "    return app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9613184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.816609Z",
     "iopub.status.busy": "2026-02-16T21:55:30.816535Z",
     "iopub.status.idle": "2026-02-16T21:55:30.884569Z",
     "shell.execute_reply": "2026-02-16T21:55:30.884288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Feb/2026 22:55:30] \"POST /infer HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Feb/2026 22:55:30] \"POST /control HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] logs crudos guardados:\n",
      " - /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/logs/raw_predictions.parquet\n",
      "[OK] filas: 0\n",
      " - /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/logs/raw_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Run: orquestacion idempotente\n",
    "# ===============================\n",
    "manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "ensure_clean_dir(runtime_dir)\n",
    "ensure_clean_dir(logs_dir)\n",
    "ensure_clean_dir(metrics_dir)\n",
    "ensure_clean_dir(report_dir)\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "app = build_runtime_server(manifest)\n",
    "server_thread = ServerThread(app, HOST, PORT)\n",
    "server_thread.start()\n",
    "\n",
    "base_url = f\"http://{HOST}:{PORT}\"\n",
    "for _ in range(50):\n",
    "    try:\n",
    "        r = requests.post(f\"{base_url}/infer\", json={\"window\": []}, timeout=2)\n",
    "        if r.status_code == 200:\n",
    "            break\n",
    "    except Exception:\n",
    "        time.sleep(0.1)\n",
    "else:\n",
    "    server_thread.shutdown()\n",
    "    raise RuntimeError(\"El servidor no ha arrancado correctamente\")\n",
    "\n",
    "raw_rows = []\n",
    "for ds in manifest[\"datasets\"]:\n",
    "    df = pd.read_parquet(ds[\"dataset_path\"])\n",
    "    if SAMPLE_SIZE:\n",
    "        df = df.head(SAMPLE_SIZE)\n",
    "        print(f\"[F07] Procesando {len(df)} ventanas (limitado por sample_size={SAMPLE_SIZE})\")\n",
    "    else:\n",
    "        print(f\"[F07] Procesando {len(df)} ventanas (dataset completo)\")\n",
    "    xcol = ds[\"x_column\"]\n",
    "    for _, row in df.iterrows():\n",
    "        window = row[xcol]\n",
    "        if hasattr(window, 'tolist'):\n",
    "            window = window.tolist()\n",
    "        resp = requests.post(f\"{base_url}/infer\", json={\"window\": window}, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        window_str = json.dumps(data[\"window\"], separators=(\",\", \":\"), ensure_ascii=False)\n",
    "        for rr in data[\"results\"]:\n",
    "            raw_rows.append({\n",
    "                \"window\": window_str,\n",
    "                \"prediction_name\": rr[\"prediction_name\"],\n",
    "                \"y_pred\": int(rr[\"y_pred\"]),\n",
    "            })\n",
    "\n",
    "raw_df = pd.DataFrame(raw_rows)\n",
    "raw_parquet_path = logs_dir / \"raw_predictions.parquet\"\n",
    "raw_csv_path = logs_dir / \"raw_predictions.csv\"\n",
    "raw_df.to_parquet(raw_parquet_path, index=False)\n",
    "raw_df.to_csv(raw_csv_path, index=False)\n",
    "\n",
    "try:\n",
    "    requests.post(f\"{base_url}/control\", json={\"cmd\": \"shutdown\"}, timeout=5)\n",
    "finally:\n",
    "    server_thread.shutdown()\n",
    "\n",
    "\n",
    "print(\"[OK] logs crudos guardados:\")\n",
    "\n",
    "print(\" -\", raw_parquet_path)\n",
    "print(\"[OK] filas:\", len(raw_df))\n",
    "print(\" -\", raw_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2817eb6",
   "metadata": {},
   "source": [
    "## 3) Postprocess - metricas por modelo (`prediction_name`) + `no_ref_*`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2287808e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.886092Z",
     "iopub.status.busy": "2026-02-16T21:55:30.886007Z",
     "iopub.status.idle": "2026-02-16T21:55:30.953969Z",
     "shell.execute_reply": "2026-02-16T21:55:30.953668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] metricas guardadas: /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/metrics/metrics_per_model.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
    "raw_df = pd.read_parquet(raw_parquet_path)\n",
    "\n",
    "# Indice rapido: (prediction_name, window_str) -> y_pred (primera aparicion)\n",
    "pred_map = {}\n",
    "for row in raw_df.itertuples(index=False):\n",
    "    key = (row.prediction_name, row.window)\n",
    "    if key not in pred_map:\n",
    "        pred_map[key] = int(row.y_pred)\n",
    "\n",
    "metrics_rows = []\n",
    "\n",
    "for m in manifest[\"models\"]:\n",
    "    pred_name = m[\"prediction_name\"]\n",
    "    dataset_path = Path(m[\"dataset_path\"])\n",
    "    xcol = m[\"x_column\"]\n",
    "    ycol = m[\"y_column\"]\n",
    "\n",
    "    df = pd.read_parquet(dataset_path)\n",
    "\n",
    "    ref_windows = set()\n",
    "    tp = tn = fp = fn = 0\n",
    "\n",
    "    for row in df.itertuples(index=False):\n",
    "        window = getattr(row, xcol)\n",
    "        if hasattr(window, 'tolist'):\n",
    "            window = window.tolist()\n",
    "        y_true = int(getattr(row, ycol))\n",
    "        window_str = json.dumps(window, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "        ref_windows.add(window_str)\n",
    "\n",
    "        y_pred = pred_map.get((pred_name, window_str))\n",
    "        if y_pred is None:\n",
    "            continue\n",
    "\n",
    "        if y_true == 1 and y_pred == 1:\n",
    "            tp += 1\n",
    "        elif y_true == 0 and y_pred == 0:\n",
    "            tn += 1\n",
    "        elif y_true == 0 and y_pred == 1:\n",
    "            fp += 1\n",
    "        elif y_true == 1 and y_pred == 0:\n",
    "            fn += 1\n",
    "\n",
    "    model_preds = raw_df[raw_df[\"prediction_name\"] == pred_name]\n",
    "    no_ref_pred_1 = int(((~model_preds[\"window\"].isin(ref_windows)) & (model_preds[\"y_pred\"] == 1)).sum())\n",
    "    no_ref_pred_0 = int(((~model_preds[\"window\"].isin(ref_windows)) & (model_preds[\"y_pred\"] == 0)).sum())\n",
    "    no_ref_total = int(no_ref_pred_0 + no_ref_pred_1)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"prediction_name\": pred_name,\n",
    "        \"source_f05\": m[\"source_f05\"],\n",
    "        \"source_f04\": m[\"source_f04\"],\n",
    "        \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"no_ref_pred_1\": no_ref_pred_1,\n",
    "        \"no_ref_pred_0\": no_ref_pred_0,\n",
    "        \"no_ref_total\": no_ref_total,\n",
    "    })\n",
    "\n",
    "    cm = np.array([[tn, fp], [fn, tp]], dtype=int)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cm)\n",
    "    plt.title(f\"Confusion - {pred_name}\")\n",
    "    plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n",
    "    plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / f\"confusion_{pred_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "metrics_csv_path = metrics_dir / \"metrics_per_model.csv\"\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "print(\"[OK] metricas guardadas:\", metrics_csv_path)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508acd70",
   "metadata": {},
   "source": [
    "## 4) Report - HTML + figuras (`report/figures/`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973ca2f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.955565Z",
     "iopub.status.busy": "2026-02-16T21:55:30.955454Z",
     "iopub.status.idle": "2026-02-16T21:55:30.959743Z",
     "shell.execute_reply": "2026-02-16T21:55:30.959490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] report: /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/report/report.html\n"
     ]
    }
   ],
   "source": [
    "def html_escape(s: str) -> str:\n",
    "    return (\n",
    "        s.replace(\"&\", \"&amp;\")\n",
    "         .replace(\"<\", \"&lt;\")\n",
    "         .replace(\">\", \"&gt;\")\n",
    "         .replace('\"', \"&quot;\")\n",
    "         .replace(\"'\", \"&#39;\")\n",
    "    )\n",
    "\n",
    "rows_html = metrics_df.to_html(index=False)\n",
    "\n",
    "imgs = []\n",
    "for m in manifest[\"models\"]:\n",
    "    pred_name = m[\"prediction_name\"]\n",
    "    img_rel = f\"figures/confusion_{pred_name}.png\"\n",
    "    img_path = figures_dir / f\"confusion_{pred_name}.png\"\n",
    "    if img_path.exists():\n",
    "        imgs.append(f\"<h3>{html_escape(pred_name)}</h3><img src='{img_rel}' style='max-width:420px;'/>\")\n",
    "\n",
    "report_html = f\"\"\"<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\"/>\n",
    "  <title>F07 Report - {html_escape(VARIANT)}</title>\n",
    "  <style>\n",
    "    body {{ font-family: Arial, sans-serif; margin: 24px; }}\n",
    "    table {{ border-collapse: collapse; }}\n",
    "    th, td {{ border: 1px solid #ddd; padding: 6px 10px; }}\n",
    "    th {{ background: #f3f3f3; }}\n",
    "    code {{ background:#f7f7f7; padding:2px 4px; }}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>F07 - Deploy & Runtime Validation</h1>\n",
    "  <p><b>Variant:</b> <code>{html_escape(VARIANT)}</code></p>\n",
    "  <p><b>Parent F06:</b> <code>{html_escape(parent_f06)}</code></p>\n",
    "  <p><b>Generated:</b> {datetime.now(timezone.utc).isoformat()}</p>\n",
    "\n",
    "  <h2>Metrics per model</h2>\n",
    "  {rows_html}\n",
    "\n",
    "  <h2>Confusion matrices</h2>\n",
    "  {''.join(imgs)}\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "report_path = report_dir / \"report.html\"\n",
    "report_path.write_text(report_html, encoding=\"utf-8\")\n",
    "print(\"[OK] report:\", report_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5b5f8",
   "metadata": {},
   "source": [
    "## 5) Trazabilidad - `07_deployrun_metadata.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d31f9e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.961221Z",
     "iopub.status.busy": "2026-02-16T21:55:30.961129Z",
     "iopub.status.idle": "2026-02-16T21:55:30.981959Z",
     "shell.execute_reply": "2026-02-16T21:55:30.981649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] metadata: /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/07_deployrun_metadata.json\n"
     ]
    }
   ],
   "source": [
    "write_metadata(\n",
    "    stage=PHASE,\n",
    "    variant=VARIANT,\n",
    "    parent_variant=parent_f06,\n",
    "    inputs=[str(manifest_path)],\n",
    "    outputs=[str(logs_dir), str(metrics_dir), str(report_dir)],\n",
    "    params=f07_params,\n",
    "    metadata_path=metadata_path,\n",
    ")\n",
    "\n",
    "print(\"[OK] metadata:\", metadata_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dedc5d6",
   "metadata": {},
   "source": [
    "## 6) Resumen de artefactos generados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27fdb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:55:30.983428Z",
     "iopub.status.busy": "2026-02-16T21:55:30.983261Z",
     "iopub.status.idle": "2026-02-16T21:55:30.985574Z",
     "shell.execute_reply": "2026-02-16T21:55:30.985354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Artefactos F07 ==\n",
      "manifest : /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/manifest.json\n",
      "logs     : /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/logs/raw_predictions.parquet /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/logs/raw_predictions.csv\n",
      "metrics  : /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/metrics/metrics_per_model.csv\n",
      "report   : /Users/juancarlosduenaslopez/Documents/mlops/mlops4ofp/executions/07_deployrun/v701/report/report.html\n"
     ]
    }
   ],
   "source": [
    "print(\"== Artefactos F07 ==\")\n",
    "print(\"manifest :\", manifest_path)\n",
    "print(\"logs     :\", raw_parquet_path, raw_csv_path)\n",
    "print(\"metrics  :\", metrics_csv_path)\n",
    "print(\"report   :\", report_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
